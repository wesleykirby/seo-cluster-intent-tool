[1mdiff --git a/cluster/semantic_analyzer.py b/cluster/semantic_analyzer.py[m
[1mindex 9ab5634..0f1708c 100644[m
[1m--- a/cluster/semantic_analyzer.py[m
[1m+++ b/cluster/semantic_analyzer.py[m
[36m@@ -353,6 +353,7 @@[m [mclass SemanticKeywordAnalyzer:[m
         results = [][m
         [m
         for keyword in keywords:[m
[32m+[m[32m<<<<<<< HEAD[m
             try:[m
                 # Check if this is a slot game or branded combination[m
                 is_slot = self.is_slot_game(keyword)[m
[36m@@ -405,8 +406,37 @@[m [mclass SemanticKeywordAnalyzer:[m
                         'Keyword': keyword[m
                     })[m
         [m
[32m+[m[32m=======[m
[32m+[m[32m            # Get fuzzy intent analysis (understands misspellings)[m
[32m+[m[32m            intent_analysis = self.fuzzy_recognizer.analyze_intent(keyword, self.brand_patterns)[m
[32m+[m
[32m+[m[32m            # Extract the components while preserving original keyword[m
[32m+[m[32m            main_topic = intent_analysis['main'][m
[32m+[m[32m            sub_topic = intent_analysis['sub'][m
[32m+[m[32m            modifier = intent_analysis['modifier'][m
[32m+[m
[32m+[m[32m            main_conf_raw = float(intent_analysis.get('main_confidence') or 0.0)[m
[32m+[m[32m            modifier_conf_raw = float(intent_analysis.get('modifier_confidence') or 0.0)[m
[32m+[m[32m            # Normalize confidences to the 0-1 range for downstream consumers[m
[32m+[m[32m            main_conf = max(0.0, min(1.0, main_conf_raw / 100.0))[m
[32m+[m[32m            modifier_conf = max(0.0, min(1.0, modifier_conf_raw / 100.0))[m
[32m+[m
[32m+[m[32m            confidence_components = [value for value in (main_conf, modifier_conf) if value > 0][m
[32m+[m[32m            intent_conf = float(sum(confidence_components) / len(confidence_components)) if confidence_components else main_conf[m
[32m+[m
[32m+[m[32m            results.append({[m
[32m+[m[32m                'Main': main_topic,  # Already properly formatted from fuzzy recognizer[m
[32m+[m[32m                'Sub': sub_topic,[m
[32m+[m[32m                'Mod': modifier,[m
[32m+[m[32m                'Keyword': keyword,  # Original keyword preserved![m
[32m+[m[32m                'main_confidence': main_conf,[m
[32m+[m[32m                'modifier_confidence': modifier_conf,[m
[32m+[m[32m                'intent_conf': intent_conf,[m
[32m+[m[32m            })[m
[32m+[m
[32m+[m[32m>>>>>>> f4ea970643a3c2ca31e12b06de7ee7aa69ddc9d9[m
         df = pd.DataFrame(results)[m
[31m-        [m
[32m+[m
         # Step 3: Add cluster IDs using semantic clustering[m
         # Group by Main+Sub for more meaningful clusters[m
         df['cluster_group'] = df['Main'] + '_' + df['Sub'][m
[36m@@ -424,11 +454,16 @@[m [mclass SemanticKeywordAnalyzer:[m
                 cluster_id += 1[m
         [m
         df['Cluster_ID'] = df['Keyword'].map(cluster_map)[m
[31m-        [m
[32m+[m
         # Clean up temporary columns[m
         df = df.drop(['cluster_group'], axis=1)[m
[32m+[m[32m<<<<<<< HEAD[m
         [m
         return df[['Main', 'Sub', 'Mod', 'Keyword']]  # Clean 4-column output[m
[32m+[m[32m=======[m
[32m+[m
[32m+[m[32m        return df[['Main', 'Sub', 'Mod', 'Keyword', 'Cluster_ID', 'main_confidence', 'modifier_confidence', 'intent_conf']][m
[32m+[m[32m>>>>>>> f4ea970643a3c2ca31e12b06de7ee7aa69ddc9d9[m
     [m
     def analyze_keywords_with_urls(self, keyword_url_pairs: List[Tuple[str, str]]) -> pd.DataFrame:[m
         """[m
[36m@@ -447,6 +482,7 @@[m [mclass SemanticKeywordAnalyzer:[m
         results = [][m
         [m
         for keyword, url in keyword_url_pairs:[m
[32m+[m[32m<<<<<<< HEAD[m
             try:[m
                 # Check if this is a slot game or branded combination[m
                 is_slot = self.is_slot_game(keyword)[m
[36m@@ -480,29 +516,52 @@[m [mclass SemanticKeywordAnalyzer:[m
                     'sub_topic': 'General',[m
                     'modifier': 'General'[m
                 }[m
[32m+[m[32m=======[m
[32m+[m[32m            # Get semantic analysis first[m
[32m+[m[32m            intent_analysis = self.fuzzy_recognizer.analyze_intent(keyword, self.brand_patterns)[m
[32m+[m
[32m+[m[32m            # Convert to format expected by URL analyzer[m
[32m+[m[32m            semantic_result = {[m
[32m+[m[32m                'main_topic': intent_analysis['main'],[m
[32m+[m[32m                'sub_topic': intent_analysis['sub'],[m
[32m+[m[32m                'modifier': intent_analysis['modifier'][m
[32m+[m[32m            }[m
[32m+[m[32m>>>>>>> f4ea970643a3c2ca31e12b06de7ee7aa69ddc9d9[m
             [m
[32m+[m[32m            main_conf_raw = float(intent_analysis.get('main_confidence') or 0.0)[m
[32m+[m[32m            modifier_conf_raw = float(intent_analysis.get('modifier_confidence') or 0.0)[m
[32m+[m[32m            main_conf = max(0.0, min(1.0, main_conf_raw / 100.0))[m
[32m+[m[32m            modifier_conf = max(0.0, min(1.0, modifier_conf_raw / 100.0))[m
[32m+[m
[32m+[m[32m            confidence_components = [value for value in (main_conf, modifier_conf) if value > 0][m
[32m+[m
             # Enhance with URL analysis if URL is provided[m
             if url and url.strip():[m
                 enhanced_result = self.url_analyzer.enhance_semantic_classification([m
                     keyword, url, semantic_result[m
                 )[m
[31m-                [m
[32m+[m
                 # Use enhanced results if available[m
                 main_topic = enhanced_result.get('main_topic', intent_analysis['main'])[m
                 sub_topic = enhanced_result.get('sub_topic', intent_analysis['sub'])[m
                 modifier = enhanced_result.get('modifier', intent_analysis['modifier'])[m
[31m-                [m
[32m+[m
                 # Track URL enhancement metadata[m
                 url_enhanced = enhanced_result.get('url_override', False)[m
[31m-                url_confidence = enhanced_result.get('url_confidence', 0)[m
[32m+[m[32m                url_confidence_raw = float(enhanced_result.get('url_confidence', 0) or 0.0)[m
[32m+[m[32m                url_confidence = max(0.0, min(1.0, url_confidence_raw / 100.0 if url_confidence_raw > 1 else url_confidence_raw))[m
[32m+[m[32m                if url_confidence > 0:[m
[32m+[m[32m                    confidence_components.append(url_confidence)[m
             else:[m
                 # Fall back to semantic-only analysis[m
                 main_topic = intent_analysis['main'][m
[31m-                sub_topic = intent_analysis['sub']  [m
[32m+[m[32m                sub_topic = intent_analysis['sub'][m
                 modifier = intent_analysis['modifier'][m
                 url_enhanced = False[m
[31m-                url_confidence = 0[m
[31m-            [m
[32m+[m[32m                url_confidence = 0.0[m
[32m+[m
[32m+[m[32m            intent_conf = float(sum(confidence_components) / len(confidence_components)) if confidence_components else main_conf[m
[32m+[m
             results.append({[m
                 'Main': main_topic,[m
                 'Sub': sub_topic,[m
[36m@@ -510,11 +569,15 @@[m [mclass SemanticKeywordAnalyzer:[m
                 'Keyword': keyword,[m
                 'URL': url,[m
                 'URL_Enhanced': url_enhanced,[m
[31m-                'URL_Confidence': url_confidence[m
[32m+[m[32m                'URL_Confidence': url_confidence,[m
[32m+[m[32m                'Cluster_ID': None,[m
[32m+[m[32m                'main_confidence': main_conf,[m
[32m+[m[32m                'modifier_confidence': modifier_conf,[m
[32m+[m[32m                'intent_conf': intent_conf,[m
             })[m
[31m-        [m
[32m+[m
         df = pd.DataFrame(results)[m
[31m-        [m
[32m+[m
         # Add cluster IDs using semantic clustering (same as original method)[m
         df['cluster_group'] = df['Main'] + '_' + df['S